{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from umap import UMAP\n",
    "import glob\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "import warnings\n",
    "import torchvision.transforms as T\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./vectorized_torch_emb_disp_up/vectorized_torch_emb/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clusterization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 34\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pt'):\n",
    "            embeddings = torch.load(os.path.join(folder_path, filename), weights_only=True)\n",
    "            embeddings = T.transforms.F.resize(embeddings.unsqueeze(0), (34, 768))\n",
    "            word_embeddings.append(embeddings)\n",
    "\n",
    "    x = [i.shape[1] for i in word_embeddings]\n",
    "    print(min(x), max(x))\n",
    "    word_embeddings = torch.cat(word_embeddings, dim=0)\n",
    "    embeddings_list = word_embeddings.squeeze().detach().numpy().mean(axis=1)\n",
    "    umap_embeddings = umap.UMAP(n_neighbors=15, min_dist=0.000001, n_components=2, metric = \"cosine\").fit_transform(embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "c = AgglomerativeClustering(n_clusters=2).fit(umap_embeddings)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    word_embeddings, \n",
    "    torch.tensor(c.labels_), \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=c.labels_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(\n",
    "    X_train, \n",
    "    torch.nn.functional.one_hot(y_train, 2)\n",
    ")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([218, 768, 33])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Conv1d(768, 768, kernel_size=2, padding=0)(word_embeddings.transpose(1,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 768])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, seq_len=2, emb_size=768):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(34, 20, kernel_size=3, padding=1),\n",
    "            torch.nn.Conv1d(20, 10, kernel_size=3, padding=1),\n",
    "            torch.nn.Conv1d(10, 1, kernel_size=3, padding=1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(768, 250),\n",
    "            torch.nn.Linear(250, 128),\n",
    "            torch.nn.Linear(128, 2),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 20, 768])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Conv1d(34, 20, kernel_size=3, padding=1)(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n",
      "0.25741976499557495\n"
     ]
    }
   ],
   "source": [
    "lm = []\n",
    "for e in range(20):\n",
    "    for x, y in dataloader_train:\n",
    "        x.detach().requir_grad = True\n",
    "        y.detach().requir_grad = True\n",
    "        o = model(x.float())\n",
    "        l = loss(o, y.float())\n",
    "        l.backward()\n",
    "        lm.append(l.item())\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "    print(np.mean(lm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4974, 0.5026],\n",
       "        [0.4970, 0.5030],\n",
       "        [0.4971, 0.5029],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4971, 0.5029],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4956, 0.5044],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4937, 0.5063],\n",
       "        [0.4950, 0.5050],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4950, 0.5050],\n",
       "        [0.4974, 0.5026],\n",
       "        [0.4950, 0.5050],\n",
       "        [0.4961, 0.5039],\n",
       "        [0.4937, 0.5063],\n",
       "        [0.4937, 0.5063],\n",
       "        [0.4971, 0.5029],\n",
       "        [0.4950, 0.5050],\n",
       "        [0.4974, 0.5026]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
